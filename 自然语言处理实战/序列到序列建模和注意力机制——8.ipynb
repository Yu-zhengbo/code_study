{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用序列到序列网络构建一个聊天机器人\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlpia.futil:Reading CSV with `read_csv(*('C:\\\\Users\\\\24132\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\nlpia\\\\data\\\\moviedialog.csv',), **{'nrows': None, 'low_memory': False})`...\n"
     ]
    }
   ],
   "source": [
    "from nlpia.loaders import get_data\n",
    "df = get_data('moviedialog')\n",
    "input_texts,target_texts = [],[]\n",
    "input_vocabulary = set()\n",
    "output_vocabulary = set()\n",
    "start_token = '\\t'\n",
    "stop_token = '\\n'\n",
    "max_training_sample = min(25000,len(df)-1)\n",
    "\n",
    "for input_text,target_text in zip(df.statement,df.reply):\n",
    "    target_text = start_token+target_text+stop_token\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_vocabulary:\n",
    "            input_vocabulary.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in output_vocabulary:\n",
    "            output_vocabulary.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入字符set之后数量： 44      输出字符set之后数量 46\n"
     ]
    }
   ],
   "source": [
    "#输入和输出词汇表\n",
    "input_vocabulary = sorted(input_vocabulary)\n",
    "output_vocabulary = sorted(output_vocabulary)\n",
    "\n",
    "input_vocab_size = len(input_vocabulary)\n",
    "output_vocab_size = len(output_vocabulary)\n",
    "max_encode_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decode_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "#建立字典\n",
    "input_token_index = dict([char,i] for i,char in enumerate(input_vocabulary))\n",
    "target_token_index = dict([char,i] for i,char in enumerate(output_vocabulary))\n",
    "reverse_input_char_index = dict((i,char) for char,i in input_token_index.items())\n",
    "reverse_output_char_index = dict((i,char) for char,i in target_token_index.items())\n",
    "\n",
    "\n",
    "print('输入字符set之后数量：',input_vocab_size,'     输出字符set之后数量',output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#生成独热编码\n",
    "import numpy as np\n",
    "encoder_input_data = np.zeros((len(input_texts),max_encode_seq_length,input_vocab_size),dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts),max_decode_seq_length,output_vocab_size),dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts),max_decode_seq_length,output_vocab_size),dtype='float32')\n",
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]] = 1\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token_index[char]] = 1\n",
    "        if t>0:\n",
    "            decoder_target_data[i,t-1,target_token_index[char]] = 1\n",
    "encoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64350"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "905/905 [==============================] - 20s 22ms/step - loss: 0.1169 - acc: 0.3246 - val_loss: 0.0012 - val_acc: 0.3581\n",
      "Epoch 2/10\n",
      "905/905 [==============================] - 19s 21ms/step - loss: 4.7715e-04 - acc: 0.3504 - val_loss: 2.2921e-04 - val_acc: 0.3581\n",
      "Epoch 3/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 1.3577e-04 - acc: 0.3504 - val_loss: 8.9970e-05 - val_acc: 0.3581\n",
      "Epoch 4/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 5.9690e-05 - acc: 0.3504 - val_loss: 4.3987e-05 - val_acc: 0.3581\n",
      "Epoch 5/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 3.0630e-05 - acc: 0.3504 - val_loss: 2.3709e-05 - val_acc: 0.3581\n",
      "Epoch 6/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 1.6952e-05 - acc: 0.3504 - val_loss: 1.3456e-05 - val_acc: 0.3581\n",
      "Epoch 7/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 9.7985e-06 - acc: 0.3504 - val_loss: 7.9314e-06 - val_acc: 0.3581\n",
      "Epoch 8/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 5.8211e-06 - acc: 0.3504 - val_loss: 4.7647e-06 - val_acc: 0.3581\n",
      "Epoch 9/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 3.5237e-06 - acc: 0.3504 - val_loss: 2.9140e-06 - val_acc: 0.3581\n",
      "Epoch 10/10\n",
      "905/905 [==============================] - 18s 20ms/step - loss: 2.1651e-06 - acc: 0.3504 - val_loss: 1.8079e-06 - val_acc: 0.3581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2520a8ec850>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,LSTM,Dense\n",
    "from keras import optimizers\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "num_neurons = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(None,input_vocab_size))   #加密输入\n",
    "encoder = LSTM(num_neurons,return_state=True)\n",
    "encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h,state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None,output_vocab_size))  #解密输入\n",
    "decoder_lstm = LSTM(num_neurons,return_sequences=True,return_state=True)\n",
    "decoder_outputs,_,_ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size,activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.fit([encoder_input_data,decoder_input_data],decoder_input_data,batch_size=batch_size,epochs=epochs,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#组装序列生成模型\n",
    "encode_model = Model(encoder_inputs,encoder_states)\n",
    "\n",
    "thought_input = [Input(shape=(num_neurons,)),Input(shape=(num_neurons,))]\n",
    "decoder_outputs,state_h,state_c = decoder_lstm(decoder_inputs,initial_state=thought_input)\n",
    "decoder_states = [state_h,state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_inputs]+thought_input,\n",
    "                     outputs=[decoder_outputs]+decoder_states)\n",
    "\n",
    "#建立字符级的翻译器\n",
    "def decode_sequence(input_seq):\n",
    "    thought = encode_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1,output_vocab_size))\n",
    "    target_seq[0,0,target_token_index[stop_token]] = 1.0\n",
    "    stop_condiction = False\n",
    "    generated_sequence = ''\n",
    "    while not stop_condiction:\n",
    "        output_tokens,h,c = decoder_model.predict([target_seq]+thought)\n",
    "        generated_token_idx = np.argmax(output_tokens[0,-1,:])\n",
    "        generated_char = reverse_output_char_index[generated_token_idx]\n",
    "        generated_sequence += generated_char\n",
    "        if (generated_char==stop_token or len(generated_sequence)>max_decode_seq_length):\n",
    "            stop_condiction = True\n",
    "        target_seq = np.zeros((1,1,output_vocab_size))\n",
    "        target_seq[0,0,generated_token_idx] = 1.0\n",
    "        thought = [h,c]\n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebot reply(Decoded sentence): \tiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n"
     ]
    }
   ],
   "source": [
    "#生成回复\n",
    "def response(input_text):\n",
    "    input_seq = np.zeros((1,max_encode_seq_length,input_vocab_size),dtype='float32')\n",
    "    for t,char in enumerate(input_text):\n",
    "        input_seq[0,t,input_token_index[char]] = 1.0\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Rebot reply(Decoded sentence):',decoded_sentence)\n",
    "\n",
    "response('what is the net?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\t',\n",
       " 1: '\\n',\n",
       " 2: ' ',\n",
       " 3: '!',\n",
       " 4: \"'\",\n",
       " 5: ',',\n",
       " 6: '.',\n",
       " 7: '0',\n",
       " 8: '1',\n",
       " 9: '2',\n",
       " 10: '3',\n",
       " 11: '4',\n",
       " 12: '5',\n",
       " 13: '6',\n",
       " 14: '7',\n",
       " 15: '8',\n",
       " 16: '9',\n",
       " 17: ':',\n",
       " 18: ';',\n",
       " 19: '?',\n",
       " 20: 'a',\n",
       " 21: 'b',\n",
       " 22: 'c',\n",
       " 23: 'd',\n",
       " 24: 'e',\n",
       " 25: 'f',\n",
       " 26: 'g',\n",
       " 27: 'h',\n",
       " 28: 'i',\n",
       " 29: 'j',\n",
       " 30: 'k',\n",
       " 31: 'l',\n",
       " 32: 'm',\n",
       " 33: 'n',\n",
       " 34: 'o',\n",
       " 35: 'p',\n",
       " 36: 'q',\n",
       " 37: 'r',\n",
       " 38: 's',\n",
       " 39: 't',\n",
       " 40: 'u',\n",
       " 41: 'v',\n",
       " 42: 'w',\n",
       " 43: 'x',\n",
       " 44: 'y',\n",
       " 45: 'z'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_output_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

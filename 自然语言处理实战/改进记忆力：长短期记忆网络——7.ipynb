{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\pugnlp\\constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
      "C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\pugnlp\\constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
      "C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\pugnlp\\tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\pugnlp\\util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "INFO:nlpia.constants:Starting logger in nlpia.constants...\n",
      "C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\nlpia\\futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\nlpia\\loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "INFO:nlpia.loaders:No BIGDATA index found in C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\nlpia\\data\\bigdata_info.csv so copy C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\nlpia\\data\\bigdata_info.latest.csv to C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\nlpia\\data\\bigdata_info.csv if you want to \"freeze\" it.\n",
      "INFO:nlpia.futil:Reading CSV with `read_csv(*('C:\\\\Users\\\\24132\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\nlpia\\\\data\\\\mavis-batey-greetings.csv',), **{'low_memory': False})`...\n",
      "INFO:nlpia.futil:Reading CSV with `read_csv(*('C:\\\\Users\\\\24132\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\nlpia\\\\data\\\\sms-spam.csv',), **{'low_memory': False})`...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'D:\\\\迅雷下载\\\\nlpia-master-源代码及下载资源\\\\dataset\\\\7.4.1- IMDB电影评论数据集\\\\aclImdb\\\\train\\\\neg\\\\6390_2.txt'),\n",
       " (1,\n",
       "  'D:\\\\迅雷下载\\\\nlpia-master-源代码及下载资源\\\\dataset\\\\7.4.1- IMDB电影评论数据集\\\\aclImdb\\\\train\\\\pos\\\\1833_10.txt'),\n",
       " (0,\n",
       "  'D:\\\\迅雷下载\\\\nlpia-master-源代码及下载资源\\\\dataset\\\\7.4.1- IMDB电影评论数据集\\\\aclImdb\\\\train\\\\neg\\\\731_3.txt'),\n",
       " (1,\n",
       "  'D:\\\\迅雷下载\\\\nlpia-master-源代码及下载资源\\\\dataset\\\\7.4.1- IMDB电影评论数据集\\\\aclImdb\\\\train\\\\pos\\\\11781_8.txt'),\n",
       " (0,\n",
       "  'D:\\\\迅雷下载\\\\nlpia-master-源代码及下载资源\\\\dataset\\\\7.4.1- IMDB电影评论数据集\\\\aclImdb\\\\train\\\\neg\\\\8140_2.txt')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import glob\n",
    "import os \n",
    "from random import shuffle\n",
    "from nlpia.loaders import get_data\n",
    "\n",
    "def pre_process_data(filepath):\n",
    "    positive_path = os.path.join(filepath,'pos')\n",
    "    negative_path = os.path.join(filepath,'neg')\n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    dataset = []\n",
    "    for filename in glob.glob(os.path.join(positive_path,'*.txt')):\n",
    "        dataset.append((pos_label,filename))\n",
    "    for filename in glob.glob(os.path.join(negative_path,'*.txt')):\n",
    "        dataset.append((neg_label,filename))\n",
    "    shuffle(dataset)\n",
    "    return dataset\n",
    "dataset = pre_process_data(r'D:\\迅雷下载\\nlpia-master-源代码及下载资源\\dataset\\7.4.1- IMDB电影评论数据集\\aclImdb\\train')\n",
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.utils_any2vec:loading projection weights from D:\\迅雷下载\\GoogleNews-vectors-negative300.bin.gz\n",
      "INFO:gensim.models.utils_any2vec:loaded (3000000, 300) matrix from D:\\迅雷下载\\GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "#加载谷歌预训练词向量\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "word_vector=KeyedVectors.load_word2vec_format(r'D:\\迅雷下载\\GoogleNews-vectors-negative300.bin.gz',binary=True)\n",
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集\n",
    "import numpy as np\n",
    "\n",
    "split_point=int(len(dataset)*0.8)\n",
    "trainData=dataset[:split_point]\n",
    "testData=dataset[split_point:]\n",
    "\n",
    "\n",
    "\n",
    "def token_and_vectorize(filename,tokenizers):       #将句子转换为词向量\n",
    "    sample_vec=[]\n",
    "    with open(filename,'r',encoding='utf-8') as f:\n",
    "        tokens=tokenizer.tokenize(f.read())\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vec.append(word_vector[token])\n",
    "            except:\n",
    "                pass\n",
    "    return sample_vec\n",
    "\n",
    "\n",
    "def collect_expected(dataset):       #得到标签\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        expected.append(sample[0])\n",
    "    return expected\n",
    "\n",
    "def pad_trunc(data,maxlen=400):      #将每个句子的词向量长度规范到400\n",
    "    zero_vector=[]\n",
    "    for _ in range(len(data[0])):\n",
    "        zero_vector.append(0.0)\n",
    "    if len(data)>maxlen:\n",
    "        temp=data[:maxlen]\n",
    "    elif len(data)<maxlen:\n",
    "        temp=data\n",
    "        additional_elems=maxlen-len(data)\n",
    "        for _ in range(additional_elems):\n",
    "            temp.append(zero_vector)\n",
    "    else:\n",
    "        temp=data\n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "def data_generator(data_store,tokenizers,batchsize=32,maxlen=400,embedding_dims=300):\n",
    "    X,Y=[],[]\n",
    "    while True:\n",
    "        for i in range(len(data_store)):\n",
    "            if (i % batchsize==0 and X and Y) or (i==len(data_store)):\n",
    "                X=np.reshape(X,(len(X),maxlen,embedding_dims))\n",
    "                Y=np.array(Y)\n",
    "                yield X,Y\n",
    "                X,Y=[],[]\n",
    "            x,y=data_store[i][1],data_store[i][0]\n",
    "            x=pad_trunc(token_and_vectorize(x,tokenizers),maxlen=maxlen)    \n",
    "            X.append(x)\n",
    "            Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 400, 50)           70200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 20001     \n",
      "=================================================================\n",
      "Total params: 90,201\n",
      "Trainable params: 90,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 181s 290ms/step - loss: 0.4324 - accuracy: 0.8034 - val_loss: 0.3548 - val_accuracy: 0.8446\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 73s 116ms/step - loss: 0.3222 - accuracy: 0.8662 - val_loss: 0.3201 - val_accuracy: 0.8636\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 73s 117ms/step - loss: 0.2756 - accuracy: 0.8864 - val_loss: 0.3349 - val_accuracy: 0.8608\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,LSTM\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "#设置CNN参数\n",
    "num_netrons = 50\n",
    "maxlen = 400\n",
    "batch_size = 32 \n",
    "embedding_dim = 300    #词向量长度\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dim = 250\n",
    "epochs = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_netrons,return_sequences=True,input_shape=(maxlen,embedding_dim)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "X_test=data_generator(testData,tokenizer,batchsize=batch_size,maxlen=maxlen)\n",
    "\n",
    "trainlen = len(trainData)\n",
    "testlen = len(testData)\n",
    "\n",
    "history=model.fit(data_generator(trainData,tokenizer,batchsize=batch_size,maxlen=maxlen),steps_per_epoch=math.ceil(trainlen/batch_size),epochs=3,validation_data=X_test,validation_steps=math.ceil(testlen/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存模型\n",
    "\n",
    "model_structure = model.to_json()\n",
    "with open(r'D:\\深度学习模型\\nlp_9.1_lstm_model.json','w')as f:\n",
    "    f.write(model_structure)\n",
    "model.save_weights(r'D:\\深度学习模型\\nlp_9.1_lstm_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "with open(r'D:\\深度学习模型\\nlp_9.1_lstm_model.json','r')as f:\n",
    "    json_string = f.read()\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights(r'D:\\深度学习模型\\nlp_9.1_lstm_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6674501]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-2144528d6e27>:24: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-2144528d6e27>:24: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import numpy as np\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "file1 = r'D:\\迅雷下载\\nlpia-master-源代码及下载资源\\dataset\\7.4.1- IMDB电影评论数据集\\aclImdb\\test\\pos\\5_7.txt'\n",
    "vec_list = token_and_vectorize(file1,tokenizer)\n",
    "\n",
    "def reshape_400(list):\n",
    "    zero_list = [0.0 for i in range(len(list[0]))]\n",
    "    if len(list)>400:\n",
    "        temp = list[:400]\n",
    "    elif len(list)<400:\n",
    "        temp = list\n",
    "        for i in range(400-len(list)):\n",
    "            temp.append(zero_list)\n",
    "    else:\n",
    "        temp = list\n",
    "    return temp\n",
    "test_vec_list = reshape_400(vec_list)\n",
    "\n",
    "test_vec = np.reshape(test_vec_list,(1,400,300))\n",
    "\n",
    "model.predict(test_vec)\n",
    "model.predict_classes(test_vec)    #     pos_label = 1 ,neg_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符级建模\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "def pre_process_data(filepath):\n",
    "    positive_path = os.path.join(filepath,'pos')\n",
    "    negative_path = os.path.join(filepath,'neg')\n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    dataset = []\n",
    "    for filename in glob.glob(os.path.join(positive_path,'*.txt')):\n",
    "        with open(filename,'r',encoding='utf-8') as f:\n",
    "            dataset.append((pos_label,f.read()))\n",
    "    for filename in glob.glob(os.path.join(negative_path,'*.txt')):\n",
    "        with open(filename,'r',encoding='utf-8') as f:\n",
    "            dataset.append((neg_label,f.read()))\n",
    "    shuffle(dataset)\n",
    "    return dataset[:10000]\n",
    "\n",
    "def collect_expected(dataset):       #得到标签\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        expected.append(sample[0])\n",
    "    return np.array(expected)\n",
    "\n",
    "\n",
    "def avg_len(data):\n",
    "    len_ = 0\n",
    "    for i in data:\n",
    "        len_ += len(i[1])\n",
    "    return len_/len(data)\n",
    "# avg_len(dataset)    #1325.06964\n",
    "\n",
    "def clean_data(data):\n",
    "    new_data = []\n",
    "    valid_char = 'abcdefghijklmnopqrsduvwxyz012345678\"\\'?!/,:; '\n",
    "    for sample in data:\n",
    "        new_sample = []\n",
    "        for i in sample[1].lower():\n",
    "            if i in valid_char:\n",
    "                new_sample.append(i)\n",
    "            else:\n",
    "                new_sample.append('UNK')\n",
    "        new_data.append(new_sample)\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def char_pad_trunc(data,maxlen=1500):\n",
    "    newdataset = []\n",
    "    for sample in data:\n",
    "        if len(sample)>maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample)<maxlen:\n",
    "            add_ = maxlen-len(sample)\n",
    "            for i in range(add_):\n",
    "                sample.append('PAD')\n",
    "            temp = sample\n",
    "        else:\n",
    "            temp = sample\n",
    "        newdataset.append(temp)\n",
    "    return newdataset\n",
    "\n",
    "def create_dicts(data):\n",
    "    chars = set()\n",
    "    for sample in data:\n",
    "        chars.update(set(sample))\n",
    "    char_indices = dict((c,i)for c,i in enumerate(chars))\n",
    "    indices_char = dict((i,c)for c,i in enumerate(chars))\n",
    "    return char_indices,indices_char\n",
    "\n",
    "def onehot_encode(dataset,char_indices,maxlen=1500):\n",
    "    x = np.zeros((len(dataset),maxlen,len(char_indices.keys())))\n",
    "    for i ,sentence in enumerate(dataset):\n",
    "        for t,char in enumerate(sentence):\n",
    "            x[i,t,indices_char[char]] = 1\n",
    "    return np.array(x)\n",
    "\n",
    "dataset = pre_process_data(r'D:\\迅雷下载\\nlpia-master-源代码及下载资源\\dataset\\7.4.1- IMDB电影评论数据集\\aclImdb\\test')\n",
    "expected = collect_expected(dataset)\n",
    "# listified_data = clean_data(dataset)\n",
    "\n",
    "common_length_data = char_pad_trunc(clean_data(dataset),maxlen=1500)\n",
    "\n",
    "char_indices,indices_char = create_dicts(common_length_data)\n",
    "# char_indices,indices_char\n",
    "common_length_data = onehot_encode(common_length_data,char_indices,1500)\n",
    "\n",
    "split = int(len(common_length_data)*0.8)\n",
    "x_train = common_length_data[:split]\n",
    "y_train = expected[:split]\n",
    "x_test = common_length_data[split:]\n",
    "y_test = expected[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 1500, 45) (8000,)\n",
      "(2000, 1500, 45) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1500, 40)          13760     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1500, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 60000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 60001     \n",
      "=================================================================\n",
      "Total params: 73,761\n",
      "Trainable params: 73,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 8s 48ms/step - loss: 0.7381 - accuracy: 0.5121 - val_loss: 0.6928 - val_accuracy: 0.5240\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.6343 - accuracy: 0.6529 - val_loss: 0.7317 - val_accuracy: 0.5240\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.5533 - accuracy: 0.7406 - val_loss: 0.7187 - val_accuracy: 0.5455\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.7756 - val_accuracy: 0.5470\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.4103 - accuracy: 0.8300 - val_loss: 0.8121 - val_accuracy: 0.5480\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.3514 - accuracy: 0.8614 - val_loss: 0.8645 - val_accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.2934 - accuracy: 0.8928 - val_loss: 0.9427 - val_accuracy: 0.5420\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.2465 - accuracy: 0.9181 - val_loss: 1.0243 - val_accuracy: 0.5375\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.2041 - accuracy: 0.9351 - val_loss: 1.1313 - val_accuracy: 0.5465\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.1669 - accuracy: 0.9511 - val_loss: 1.2188 - val_accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,Flatten,LSTM\n",
    "import math\n",
    "\n",
    "batch_size = 50\n",
    "num_neurons = 40\n",
    "maxlen = 1500\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_neurons,return_sequences=True,input_shape=(maxlen,len(char_indices.keys()))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile('rmsprop','binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,batch_size=batch_size,epochs=10,validation_data=(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成文本_莎士比亚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文章总字符数为： 375542    set之后的字符数： 50\n",
      "sequence长度为： 125168\n",
      "next长度为： 125168\n"
     ]
    }
   ],
   "source": [
    "#预处理莎士比亚的戏剧\n",
    "text = ''\n",
    "for txt in gutenberg.fileids():\n",
    "    if 'shakespeare' in txt:\n",
    "        text += gutenberg.raw(txt).lower()\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c,i) for i,c in enumerate(chars))\n",
    "indices_char = dict((i,c) for i,c in enumerate(chars))\n",
    "print('文章总字符数为：',len(text),'   set之后的字符数：',len(chars))\n",
    "\n",
    "#数据细分为半冗余块\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentence = []\n",
    "next_char = []\n",
    "for i in range(0,len(text)-maxlen,step):\n",
    "    sentence.append(text[i:i+maxlen])\n",
    "    next_char.append(text[i+maxlen])\n",
    "print('sequence长度为：',len(sentence))\n",
    "print('next长度为：',len(next_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将训练样本转化为独热编码\n",
    "import numpy as np\n",
    "x = np.zeros((len(sentence),maxlen,len(chars)),dtype=np.bool)\n",
    "y = np.zeros((len(sentence),len(chars)),dtype=np.bool)\n",
    "for i,sent in enumerate(sentence):\n",
    "    for t,char in enumerate(sent):\n",
    "        x[i,t,char_indices[char]] = 1\n",
    "    y[i,char_indices[next_char[i]]] = 1\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 98,098\n",
      "Trainable params: 98,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#组装一个LSTM模型来生成文本\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(maxlen,len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1701"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 2.0379\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.6842\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.5806\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.5188\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.4774\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.4456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d85c91ac0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.4208\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3997\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3849\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3685\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3595\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d65e6f250>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3391\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3296\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3245\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3158\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3078\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.3017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d65ebb6d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2939\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2900\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2873\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2821\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2764\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d65f0aca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2708\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2634\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2600\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2586\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 4s 4ms/step - loss: 1.2525\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 5s 5ms/step - loss: 1.2504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21ebcee6d90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 6\n",
    "batch_size = 128\n",
    "model_structures = model.to_json()\n",
    "with open(r'D:\\深度学习模型\\shakes_lstm_model.json','w') as f:\n",
    "    f.write(model_structures)\n",
    "for i in range(5):\n",
    "    model.fit(x,y,batch_size=batch_size,epochs=epoch)\n",
    "    model.save_weights(r'D:\\深度学习模型\\shakes_lstm_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------diversity: 0.2\n",
      "generating with seed: \" ing; and when\n",
      "you are ask't this questio \"\n",
      "ing; and when\n",
      "you are ask't this question to day of the secesse,\n",
      "and the spend a bong, and the call the sword\n",
      "\n",
      "   cassi. i will not see the sword to the thing: you are the thing:\n",
      "there is not the soule be a followes to thee\n",
      "interpresent the stormes, and can be showes?\n",
      "that the strike to the stormes, and stay the chance\n",
      "to the stormes against the countrius, and then\n",
      "\n",
      "   cassi. there's me be so much will forgles of the selfe,\n",
      "and the call---------diversity: 0.5\n",
      "generating with seed: \" ing; and when\n",
      "you are ask't this questio \"\n",
      "ing; and when\n",
      "you are ask't this question make all,\n",
      "and then caesars breath against the fire,\n",
      "and his stome death, and the clouds of there.\n",
      "but was to the charme, and play you booke me\n",
      "with more the be commonstance of the countens,\n",
      "and hee in the cause of thine, for the scele patt and by men\n",
      "\n",
      "   ham. no my lord\n",
      "\n",
      "   ham. i thanke you make against the mother to such a forme.\n",
      "\n",
      "exeunt.\n",
      "\n",
      "enter caesar shall thing, he will be actantle\n",
      "\n",
      "   ham.---------diversity: 1.0\n",
      "generating with seed: \" ing; and when\n",
      "you are ask't this questio \"\n",
      "ing; and when\n",
      "you are ask't this question as away, i haue aratur\n",
      "tquaters, thou did been too theny selfe,\n",
      "you shars'd guilty, for it grobtes, thepes, for pretted pllast king'd\n",
      "hath of a nothing for my encorne, i do fellow,\n",
      "that take a fifirallow leape;\n",
      "gather chilsmion's cormingesse hath caesar.\n",
      "i haue knowe his nature, it naugtyr goue with\n",
      "the keepe, and their comminder blow'd thy generate,\n",
      "and dey not manue right you vp: and treached,"
     ]
    }
   ],
   "source": [
    "import random \n",
    "def sample(preds,temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)/temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1,preds,1)    #可以模拟随机实验\n",
    "    return np.argmax(probas)\n",
    "\n",
    "import sys \n",
    "start_index = random.randint(0,len(text)-maxlen-1)\n",
    "for diversity in [0.2,0.5,1.0]:\n",
    "    print('---------diversity:',diversity)\n",
    "    generated = ''\n",
    "    sentence = text[start_index:start_index+maxlen]\n",
    "    generated += sentence\n",
    "    print('generating with seed:','\"',generated,'\"')\n",
    "    sys.stdout.write(generated)\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1,maxlen,len(chars)))\n",
    "        for t,char in enumerate(sentence):\n",
    "            x[0,t,char_indices[char]] = 1.\n",
    "        preds = model.predict(x,verbose=0)[0]\n",
    "        next_index = sample(preds,diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:]+next_char\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 想写迭代器来训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,Flatten,LSTM\n",
    "import math\n",
    "\n",
    "batch_size = 50\n",
    "num_neurons = 40\n",
    "maxlen = 1500\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_neurons,return_sequences=True,input_shape=(maxlen,len(char_indices.keys()))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile('rmsprop','binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "X_test=generate_onehot(testData,char_indices,maxlen=maxlen)\n",
    "\n",
    "trainlen = len(trainData)\n",
    "testlen = len(testData)\n",
    "\n",
    "history=model.fit(generate_onehot(trainData,char_indices,maxlen=maxlen),steps_per_epoch=math.ceil(trainlen/batch_size),epochs=3,validation_data=X_test,validation_steps=math.ceil(testlen/batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_indices\n",
    "# for i in common_length_data:\n",
    "#     print(len(i))\n",
    "trainData = common_length_data[:int(len(common_length_data)*0.8)]\n",
    "testData = common_length_data[int(len(common_length_data)*0.8):]\n",
    "def generate_onehot(dataset,char_indices,maxlen=1500,batch=50):\n",
    "    x = np.zeros((batch,maxlen,len(char_indices.keys())))\n",
    "    step = int(len(dataset)/batch)\n",
    "    while True:\n",
    "        for j in range(step):\n",
    "            for i,sentence in enumerate(dataset[j*batch:(j+1)*batch]):\n",
    "#             print(i,sentence)\n",
    "                 for t,char in enumerate(sentence):\n",
    "#                 print(len(sentence))\n",
    "                      x[i,t,indices_char[char]] = 1\n",
    "        yield x\n",
    "\n",
    "encoded_data = generate_onehot(common_length_data,char_indices,maxlen=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1500, 45)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# char_indices\n",
    "a = np.array(next(encoded_data))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1500, 40)          13760     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1500, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 60000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 60001     \n",
      "=================================================================\n",
      "Total params: 73,761\n",
      "Trainable params: 73,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756 train_step\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2736 _minimize\n        gradients = optimizer._aggregate_gradients(zip(gradients,  # pylint: disable=protected-access\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:562 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1270 _filter_grads\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['lstm_4/lstm_cell_4/kernel:0', 'lstm_4/lstm_cell_4/recurrent_kernel:0', 'lstm_4/lstm_cell_4/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-55f8b7899d47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtestlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_onehot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainlen\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestlen\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756 train_step\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2736 _minimize\n        gradients = optimizer._aggregate_gradients(zip(gradients,  # pylint: disable=protected-access\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:562 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\24132\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1270 _filter_grads\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['lstm_4/lstm_cell_4/kernel:0', 'lstm_4/lstm_cell_4/recurrent_kernel:0', 'lstm_4/lstm_cell_4/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,Flatten,LSTM\n",
    "import math\n",
    "\n",
    "batch_size = 50\n",
    "num_neurons = 40\n",
    "maxlen = 1500\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_neurons,return_sequences=True,input_shape=(maxlen,len(char_indices.keys()))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile('rmsprop','binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "X_test=generate_onehot(testData,char_indices,maxlen=maxlen)\n",
    "\n",
    "trainlen = len(trainData)\n",
    "testlen = len(testData)\n",
    "\n",
    "history=model.fit(generate_onehot(trainData,char_indices,maxlen=maxlen),steps_per_epoch=math.ceil(trainlen/batch_size),epochs=3,validation_data=X_test,validation_steps=math.ceil(testlen/batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokens长度：', 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('and', 4), ('with', 2), ('friends', 2), (',', 2), ('to', 2)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.08695652173913043"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('去停用词后tokens长度：', 18)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('friends', 2), (',', 2), ('keeping', 1), ('faster', 1), ('easier', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#词袋\n",
    "from nltk.tokenize import TreebankWordTokenizer   #分词\n",
    "from collections import Counter\n",
    "\n",
    "sentence = \"\"\"Keeping up with friends is faster and easier than ever. Share updates and photos, engage with friends and Pages, and stay connected to communities important to you.\"\"\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(sentence.lower())  #分词的结果\n",
    "'tokens长度：',len(tokens)\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words.most_common(5)\n",
    "TF = bag_of_words['friends']/len(bag_of_words)  #词项频率\n",
    "TF\n",
    "\n",
    "#去停用词\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokens = [i for i in tokens if i not in stopwords]\n",
    "'去停用词后tokens长度：',len(tokens)\n",
    "bag_1 = Counter(tokens)\n",
    "bag_1.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('.', 0.03125),\n",
       "              ('also', 0),\n",
       "              ('and', 0.03125),\n",
       "              ('app', 0),\n",
       "              ('are', 0),\n",
       "              ('around', 0),\n",
       "              ('available', 0),\n",
       "              ('current', 0),\n",
       "              ('desktop', 0),\n",
       "              ('easier', 0.03125),\n",
       "              ('events', 0),\n",
       "              ('ever', 0.03125),\n",
       "              ('facebook', 0),\n",
       "              ('faster', 0.03125),\n",
       "              ('features', 0),\n",
       "              ('friends', 0.03125),\n",
       "              ('helps', 0),\n",
       "              ('important', 0),\n",
       "              ('is', 0.03125),\n",
       "              ('keep', 0),\n",
       "              ('keeping', 0.03125),\n",
       "              ('latest', 0),\n",
       "              ('most', 0),\n",
       "              ('news', 0),\n",
       "              ('of', 0),\n",
       "              ('on', 0),\n",
       "              ('than', 0.03125),\n",
       "              ('the', 0),\n",
       "              ('up', 0.03125),\n",
       "              ('with', 0.03125),\n",
       "              ('world', 0),\n",
       "              ('you', 0)]),\n",
       " OrderedDict([('.', 0.03125),\n",
       "              ('also', 0.03125),\n",
       "              ('and', 0),\n",
       "              ('app', 0.03125),\n",
       "              ('are', 0.03125),\n",
       "              ('around', 0),\n",
       "              ('available', 0.03125),\n",
       "              ('current', 0),\n",
       "              ('desktop', 0.03125),\n",
       "              ('easier', 0),\n",
       "              ('events', 0),\n",
       "              ('ever', 0),\n",
       "              ('facebook', 0.03125),\n",
       "              ('faster', 0),\n",
       "              ('features', 0.03125),\n",
       "              ('friends', 0),\n",
       "              ('helps', 0),\n",
       "              ('important', 0.03125),\n",
       "              ('is', 0),\n",
       "              ('keep', 0),\n",
       "              ('keeping', 0),\n",
       "              ('latest', 0),\n",
       "              ('most', 0.03125),\n",
       "              ('news', 0),\n",
       "              ('of', 0.03125),\n",
       "              ('on', 0.03125),\n",
       "              ('than', 0),\n",
       "              ('the', 0.0625),\n",
       "              ('up', 0),\n",
       "              ('with', 0),\n",
       "              ('world', 0),\n",
       "              ('you', 0)]),\n",
       " OrderedDict([('.', 0.03125),\n",
       "              ('also', 0.03125),\n",
       "              ('and', 0.03125),\n",
       "              ('app', 0),\n",
       "              ('are', 0),\n",
       "              ('around', 0.03125),\n",
       "              ('available', 0),\n",
       "              ('current', 0.03125),\n",
       "              ('desktop', 0),\n",
       "              ('easier', 0),\n",
       "              ('events', 0.03125),\n",
       "              ('ever', 0),\n",
       "              ('facebook', 0.03125),\n",
       "              ('faster', 0),\n",
       "              ('features', 0),\n",
       "              ('friends', 0),\n",
       "              ('helps', 0.03125),\n",
       "              ('important', 0),\n",
       "              ('is', 0),\n",
       "              ('keep', 0.03125),\n",
       "              ('keeping', 0),\n",
       "              ('latest', 0.03125),\n",
       "              ('most', 0),\n",
       "              ('news', 0.03125),\n",
       "              ('of', 0),\n",
       "              ('on', 0),\n",
       "              ('than', 0),\n",
       "              ('the', 0.0625),\n",
       "              ('up', 0.03125),\n",
       "              ('with', 0.03125),\n",
       "              ('world', 0.03125),\n",
       "              ('you', 0.03125)])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#向量化  TF\n",
    "from nltk.tokenize import TreebankWordTokenizer   #分词\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "sentence = ['Keeping up with friends is faster and easier than ever. ']\n",
    "sentence.append('The most important desktop features of Facebook are also available on the app.')\n",
    "sentence.append('Facebook also helps you keep up with the latest news and current events around the world.')\n",
    "doc_token = []\n",
    "for doc in sentence:\n",
    "    doc_token .append(sorted(tokenizer.tokenize(doc.lower())))\n",
    "len(doc_token[0]),len(doc_token[1]),len(doc_token[2])\n",
    "all_doc_tokens = sum(doc_token,[])     #将所有文档合并\n",
    "len(all_doc_tokens)\n",
    "lexicon = sorted(set(all_doc_tokens))\n",
    "len(lexicon)\n",
    "\n",
    "from collections import OrderedDict\n",
    "zero_vector = OrderedDict((token,0) for token in lexicon)\n",
    "zero_vector\n",
    "\n",
    "import copy \n",
    "doc_vectors = []\n",
    "for doc in sentence:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key,value in token_counts.items():\n",
    "        vec[key] = value/len(lexicon)\n",
    "    doc_vectors.append(vec)\n",
    "doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('.', 0.03125),\n",
       "              ('also', 0),\n",
       "              ('and', 0.046875),\n",
       "              ('app', 0),\n",
       "              ('are', 0),\n",
       "              ('around', 0),\n",
       "              ('available', 0),\n",
       "              ('current', 0),\n",
       "              ('desktop', 0),\n",
       "              ('easier', 0.09375),\n",
       "              ('events', 0),\n",
       "              ('ever', 0.09375),\n",
       "              ('facebook', 0),\n",
       "              ('faster', 0.09375),\n",
       "              ('features', 0),\n",
       "              ('friends', 0.09375),\n",
       "              ('helps', 0),\n",
       "              ('important', 0),\n",
       "              ('is', 0.09375),\n",
       "              ('keep', 0),\n",
       "              ('keeping', 0.0),\n",
       "              ('latest', 0),\n",
       "              ('most', 0),\n",
       "              ('news', 0),\n",
       "              ('of', 0),\n",
       "              ('on', 0),\n",
       "              ('than', 0.09375),\n",
       "              ('the', 0),\n",
       "              ('up', 0.046875),\n",
       "              ('with', 0.046875),\n",
       "              ('world', 0),\n",
       "              ('you', 0)]),\n",
       " OrderedDict([('.', 0.03125),\n",
       "              ('also', 0.046875),\n",
       "              ('and', 0),\n",
       "              ('app', 0.09375),\n",
       "              ('are', 0.09375),\n",
       "              ('around', 0),\n",
       "              ('available', 0.09375),\n",
       "              ('current', 0),\n",
       "              ('desktop', 0.09375),\n",
       "              ('easier', 0),\n",
       "              ('events', 0),\n",
       "              ('ever', 0),\n",
       "              ('facebook', 0.0),\n",
       "              ('faster', 0),\n",
       "              ('features', 0.09375),\n",
       "              ('friends', 0),\n",
       "              ('helps', 0),\n",
       "              ('important', 0.09375),\n",
       "              ('is', 0),\n",
       "              ('keep', 0),\n",
       "              ('keeping', 0),\n",
       "              ('latest', 0),\n",
       "              ('most', 0.09375),\n",
       "              ('news', 0),\n",
       "              ('of', 0.09375),\n",
       "              ('on', 0.09375),\n",
       "              ('than', 0),\n",
       "              ('the', 0.09375),\n",
       "              ('up', 0),\n",
       "              ('with', 0),\n",
       "              ('world', 0),\n",
       "              ('you', 0)]),\n",
       " OrderedDict([('.', 0.03125),\n",
       "              ('also', 0.046875),\n",
       "              ('and', 0.046875),\n",
       "              ('app', 0),\n",
       "              ('are', 0),\n",
       "              ('around', 0.09375),\n",
       "              ('available', 0),\n",
       "              ('current', 0.09375),\n",
       "              ('desktop', 0),\n",
       "              ('easier', 0),\n",
       "              ('events', 0.09375),\n",
       "              ('ever', 0),\n",
       "              ('facebook', 0.0),\n",
       "              ('faster', 0),\n",
       "              ('features', 0),\n",
       "              ('friends', 0),\n",
       "              ('helps', 0.09375),\n",
       "              ('important', 0),\n",
       "              ('is', 0),\n",
       "              ('keep', 0.09375),\n",
       "              ('keeping', 0),\n",
       "              ('latest', 0.09375),\n",
       "              ('most', 0),\n",
       "              ('news', 0.09375),\n",
       "              ('of', 0),\n",
       "              ('on', 0),\n",
       "              ('than', 0),\n",
       "              ('the', 0.09375),\n",
       "              ('up', 0.046875),\n",
       "              ('with', 0.046875),\n",
       "              ('world', 0.09375),\n",
       "              ('you', 0.09375)])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量化  TF-IDF\n",
    "document_tfidf_vectors = []\n",
    "for doc in sentence:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_count = Counter(tokens)\n",
    "    for key,value in token_count.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in sentence:\n",
    "            if key in _doc:\n",
    "                docs_containing_key += 1\n",
    "        tf = value/len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(sentence)/docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf * idf\n",
    "    document_tfidf_vectors.append(vec)\n",
    "document_tfidf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42683279491835413"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.06708203932499368"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "query = 'Contact with your friends'\n",
    "query_vec = copy.copy(zero_vector)\n",
    "tokens = tokenizer.tokenize(query.lower())\n",
    "token_count = Counter(tokens)\n",
    "\n",
    "for key,value in token_count.items():\n",
    "    docs_containing_key = 0\n",
    "    for doc_ in sentence:\n",
    "        if key in doc_:\n",
    "            docs_containing_key += 1\n",
    "    if docs_containing_key == 0:\n",
    "        continue\n",
    "    tf = value/len(tokens)\n",
    "    idf = len(sentence)/docs_containing_key\n",
    "    query_vec[key] = tf * idf\n",
    "\n",
    "def cosine_sim(x,x1):\n",
    "    x = [i for i in x.values()]\n",
    "    x1 = [i for i in x1.values()]\n",
    "    a ,a1,a2= 0,0,0\n",
    "    for i in range(len(x)):\n",
    "        a += x[i]*x1[i]\n",
    "        a1 += x[i]**2\n",
    "        a2 += x1[i]**2\n",
    "    return a/(a1**(1/2)*a2**(1/2))\n",
    "cosine_sim(query_vec,document_tfidf_vectors[0])\n",
    "cosine_sim(query_vec,document_tfidf_vectors[1])\n",
    "cosine_sim(query_vec,document_tfidf_vectors[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.26, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.34,\n",
       "        0.  , 0.34, 0.  , 0.34, 0.  , 0.  , 0.34, 0.  , 0.34, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.34, 0.  , 0.26, 0.26, 0.  , 0.  ],\n",
       "       [0.22, 0.  , 0.28, 0.28, 0.  , 0.28, 0.  , 0.28, 0.  , 0.  , 0.  ,\n",
       "        0.22, 0.  , 0.28, 0.  , 0.  , 0.28, 0.  , 0.  , 0.  , 0.  , 0.28,\n",
       "        0.  , 0.28, 0.28, 0.  , 0.43, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.2 , 0.2 , 0.  , 0.  , 0.27, 0.  , 0.27, 0.  , 0.  , 0.27, 0.  ,\n",
       "        0.2 , 0.  , 0.  , 0.  , 0.27, 0.  , 0.  , 0.27, 0.  , 0.27, 0.  ,\n",
       "        0.27, 0.  , 0.  , 0.  , 0.4 , 0.2 , 0.2 , 0.27, 0.27]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sentence = ['Keeping up with friends is faster and easier than ever. ']\n",
    "sentence.append('The most important desktop features of Facebook are also available on the app.')\n",
    "sentence.append('Facebook also helps you keep up with the latest news and current events around the world.')\n",
    "corpus = sentence\n",
    "Vectorizer = TfidfVectorizer(min_df=1)\n",
    "model = Vectorizer.fit_transform(corpus)\n",
    "model.todense().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('the', 69971),\n",
       " ('of', 36412),\n",
       " ('and', 28853),\n",
       " ('to', 26158),\n",
       " ('a', 23195),\n",
       " ('in', 21337),\n",
       " ('that', 10594),\n",
       " ('is', 10109),\n",
       " ('was', 9815),\n",
       " ('he', 9548),\n",
       " ('for', 9489),\n",
       " ('it', 8760),\n",
       " ('with', 7289),\n",
       " ('as', 7253),\n",
       " ('his', 6996),\n",
       " ('on', 6741),\n",
       " ('be', 6377),\n",
       " ('at', 5372),\n",
       " ('by', 5306),\n",
       " ('i', 5164)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#齐普夫定律：在给定的自然语言语料库中，任何一个词的频率与它在频率表中的排名成反比\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "# brown.words()[:10]\n",
    "brown.tagged_words()[:5]\n",
    "puncs = string.punctuation\n",
    "puncs += '``'\n",
    "puncs += '\\'\\''\n",
    "word_list = [x.lower() for x in brown.words() if x not in puncs]\n",
    "tokens_count = Counter(word_list)\n",
    "tokens_count.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
